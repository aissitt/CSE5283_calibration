{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7235b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install opencv-python-headless gradio matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cd5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ad2d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arian\\.conda\\envs\\calibration\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, io, json, glob, math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gradio as gr\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# A1 imports\n",
    "try:\n",
    "    from calibration.calib_io import load_calibration_json, save_calibration_json\n",
    "except Exception:\n",
    "    # fallback tiny loaders to avoid breaking if A1 signatures differ\n",
    "    def load_calibration_json(path:str):\n",
    "        with open(path, \"r\") as f:\n",
    "            d = json.load(f)\n",
    "        K = np.array(d[\"K\"], float)\n",
    "        dist = np.array(d[\"dist\"], float)\n",
    "        # Fallback: no image size info, so return None\n",
    "        return K, dist, None\n",
    "    def save_calibration_json(path:str, K, dist):\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump({\"K\": np.asarray(K, float).tolist(),\n",
    "                       \"dist\": np.asarray(dist, float).reshape(-1).tolist()}, f, indent=2)\n",
    "\n",
    "# A2 imports \n",
    "from planar_pose.homography import dlt_homography_ransac\n",
    "from planar_pose.pose_from_homography import pose_from_homography\n",
    "from planar_pose.opencv_pose import pose_solvepnp, pose_from_h_decompose\n",
    "from planar_pose.model_points import load_model_points, generate_checkerboard\n",
    "from planar_pose.viz import overlay_points_and_axes, plot_3d_poses\n",
    "from planar_pose.compare import rotation_angle_diff, translation_dir_angle, reprojection_error\n",
    "from planar_pose.clicks import ClickStore\n",
    "\n",
    "# Repo images listing\n",
    "def list_repo_images():\n",
    "    return sorted(glob.glob(\"data/images/*.*\"))\n",
    "\n",
    "# Draw small numeric labels on a preview image (for click status)\n",
    "def draw_indexed_points(bgr, pts, color=(0,255,255)):\n",
    "    out = bgr.copy()\n",
    "    for i,(u,v) in enumerate(pts):\n",
    "        cv2.circle(out, (int(u),int(v)), 5, color, -1)\n",
    "        cv2.putText(out, str(i), (int(u)+6,int(v)-6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
    "    return out\n",
    "\n",
    "# Pretty-print matrices\n",
    "def fmt_rt(R, t):\n",
    "    R = np.asarray(R, float)\n",
    "    t = np.asarray(t, float).reshape(3,1)\n",
    "    return (f\"R =\\n{np.array2string(R, precision=4, suppress_small=True)}\\n\\n\"\n",
    "            f\"t =\\n{np.array2string(t.reshape(-1), precision=4, suppress_small=True)}\")\n",
    "\n",
    "# Small helper: convert Matplotlib fig to bytes\n",
    "def fig_to_png_bytes(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\", dpi=120)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return buf.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afce28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners_on_images(image_files, inner_cols, inner_rows):\n",
    "    pattern_size = (inner_cols, inner_rows)  # OpenCV INNER corners\n",
    "    objp = np.zeros((inner_rows*inner_cols,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:inner_cols, 0:inner_rows].T.reshape(-1,2)\n",
    "\n",
    "    objpoints, imgpoints = [], []\n",
    "    out_previews = []\n",
    "    used_paths = []\n",
    "\n",
    "    for p in image_files:\n",
    "        img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "        if img is None: \n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, flags=cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "        if not ret:\n",
    "            out_previews.append(img)\n",
    "            continue\n",
    "        # refine\n",
    "        corners = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria=(cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "        objpoints.append(objp.copy())\n",
    "        imgpoints.append(corners)\n",
    "        prev = img.copy()\n",
    "        cv2.drawChessboardCorners(prev, pattern_size, corners, True)\n",
    "        out_previews.append(prev)\n",
    "        used_paths.append(p)\n",
    "\n",
    "    return objpoints, imgpoints, out_previews, used_paths\n",
    "\n",
    "def calibrate_chessboard(image_files, inner_cols, inner_rows, square_size_m, preview_size=640):\n",
    "    objpoints, imgpoints, previews, used_paths = find_corners_on_images(image_files, inner_cols, inner_rows)\n",
    "    if len(objpoints) < 3:\n",
    "        return None, None, None, f\"Found chessboard on only {len(objpoints)} images. Need >=3.\"\n",
    "\n",
    "    # scale objpoints to meters\n",
    "    for i in range(len(objpoints)):\n",
    "        objpoints[i][:,:2] *= float(square_size_m)\n",
    "\n",
    "    img0 = cv2.imread(used_paths[0], cv2.IMREAD_COLOR)\n",
    "    h, w = img0.shape[:2]\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (w,h), None, None)\n",
    "\n",
    "    # per-image reprojection errors\n",
    "    per_img_err = []\n",
    "    for i in range(len(objpoints)):\n",
    "        imgpts, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], K, dist)\n",
    "        e = cv2.norm(imgpoints[i], imgpts, cv2.NORM_L2) / len(imgpts)\n",
    "        per_img_err.append(float(e))\n",
    "    rms = float(ret)\n",
    "    summary = {\"rms\": rms, \"mean_per_image_rmse\": float(np.mean(per_img_err)), \"num_images\": len(objpoints)}\n",
    "\n",
    "    # resize previews\n",
    "    out = []\n",
    "    for im in previews:\n",
    "        scale = preview_size / max(im.shape[:2])\n",
    "        im = cv2.resize(im, (int(im.shape[1]*scale), int(im.shape[0]*scale)))\n",
    "        out.append(im)\n",
    "\n",
    "    return K, dist, out, json.dumps(summary, indent=2)\n",
    "\n",
    "def undistort_preview(img_bgr, K, dist, alpha=0.85):\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    newK, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), alpha, (w,h), centerPrincipalPoint=True)\n",
    "    und = cv2.undistort(img_bgr, K, dist, None, newK)\n",
    "    return und, newK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99127003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://925e594a120e4f8c2e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "* Running on public URL: https://925e594a120e4f8c2e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://925e594a120e4f8c2e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://925e594a120e4f8c2e.gradio.live\n"
     ]
    }
   ],
   "source": [
    "# Global (per-session) state\n",
    "click_store = ClickStore()\n",
    "R_h_t = None   # (R_h, t_h)\n",
    "R_o_t = None   # (R_o, t_o)\n",
    "newK_cache = None\n",
    "current_canvas_rgb = None\n",
    "\n",
    "def _bytes_from_bgr(bgr):\n",
    "    ok, buf = cv2.imencode(\".png\", bgr)\n",
    "    return buf.tobytes() if ok else None\n",
    "\n",
    "def list_repo_images():\n",
    "    # Use absolute path for image listing, compatible with notebook (no __file__)\n",
    "    img_dir = os.path.abspath(os.path.join(os.getcwd(), \"data\", \"images\"))\n",
    "    return sorted(glob.glob(os.path.join(img_dir, \"*.*\")))\n",
    "\n",
    "def fig_to_bgr_array(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\", dpi=120)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    arr = np.frombuffer(buf.getvalue(), np.uint8)\n",
    "    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "# ---------- TAB 1: CALIBRATION (A1-like) ----------\n",
    "def tab1_list_repo_images():\n",
    "    return list_repo_images()\n",
    "\n",
    "def tab1_run_calibrate(repo_paths, uploaded_images, inner_cols, inner_rows, square_size_m):\n",
    "    files = []\n",
    "    files += repo_paths or []\n",
    "    files += [f.name for f in uploaded_images] if uploaded_images else []\n",
    "    files = [p for p in files if os.path.exists(p)]\n",
    "    if not files:\n",
    "        return None, None, None, \"No images provided.\"\n",
    "\n",
    "    K, dist, previews, summary = calibrate_chessboard(files, inner_cols, inner_rows, square_size_m)\n",
    "    if K is None:\n",
    "        return None, None, None, summary\n",
    "\n",
    "    # pass previews as numpy arrays (OpenCV images) for Gradio Gallery\n",
    "    gallery = [im for im in previews]\n",
    "    return json.dumps(K.tolist(), indent=2), json.dumps(dist.reshape(-1).tolist(), indent=2), gallery, summary\n",
    "\n",
    "def tab1_undistort_single(image_file, K_json, dist_json, alpha):\n",
    "    if image_file is None:\n",
    "        return None, None\n",
    "    K = np.array(json.loads(K_json), float)\n",
    "    dist = np.array(json.loads(dist_json), float).reshape(-1,1)\n",
    "    # Handle Gradio file input: file-like or string path\n",
    "    if hasattr(image_file, \"read\"):\n",
    "        data = image_file.read()\n",
    "    else:\n",
    "        data = open(image_file, \"rb\").read()\n",
    "    img = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    und, newK = undistort_preview(img, K, dist, alpha=float(alpha))\n",
    "    # Return numpy array for Gradio Image\n",
    "    return und, json.dumps(newK.tolist(), indent=2)\n",
    "\n",
    "def tab1_save_intrinsics(save_path, K_json, dist_json):\n",
    "    try:\n",
    "        K = np.array(json.loads(K_json), float)\n",
    "        dist = np.array(json.loads(dist_json), float).reshape(-1,1)\n",
    "        import inspect\n",
    "        # Ensure parent directory exists\n",
    "        parent_dir = os.path.dirname(save_path)\n",
    "        if parent_dir and not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir, exist_ok=True)\n",
    "        num_args = len(inspect.signature(save_calibration_json).parameters)\n",
    "        if num_args == 3:\n",
    "            save_calibration_json(save_path, K, dist)\n",
    "        else:\n",
    "            # fallback expects (path, dict) but must open file for writing\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump({\"K\": K.tolist(), \"dist\": dist.reshape(-1).tolist()}, f, indent=2)\n",
    "        return f\"Saved intrinsics to: {save_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to save: {e}\"\n",
    "\n",
    "# ---------- TAB 2: MODEL PLANE ----------\n",
    "def tab2_generate_checker(cols, rows, square_size_m):\n",
    "    XY = generate_checkerboard(int(cols), int(rows), float(square_size_m))\n",
    "    # quick preview plot with numbers\n",
    "    fig = plt.figure(figsize=(3.5,3.5))\n",
    "    plt.scatter(XY[:,0], XY[:,1], s=20)\n",
    "    for i,(x,y) in enumerate(XY):\n",
    "        plt.text(x, y, str(i), fontsize=8)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.title(\"Model points (Z=0)\")\n",
    "    plt.xlabel(\"X (m)\"); plt.ylabel(\"Y (m)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    img_bgr = fig_to_bgr_array(fig)\n",
    "    return img_bgr, json.dumps(XY.tolist(), indent=2)\n",
    "\n",
    "def tab2_load_model(file):\n",
    "    XY = load_model_points(file.name)\n",
    "    # same preview\n",
    "    fig = plt.figure(figsize=(3.5,3.5))\n",
    "    plt.scatter(XY[:,0], XY[:,1], s=20)\n",
    "    for i,(x,y) in enumerate(XY):\n",
    "        plt.text(x, y, str(i), fontsize=8)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.title(\"Loaded model points\")\n",
    "    plt.xlabel(\"X (m)\"); plt.ylabel(\"Y (m)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    img_bgr = fig_to_bgr_array(fig)\n",
    "    return img_bgr, json.dumps(XY.tolist(), indent=2)\n",
    "\n",
    "def tab2_save_model(save_path, XY_json):\n",
    "    try:\n",
    "        XY = np.array(json.loads(XY_json), float)\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        np.savetxt(save_path, XY, delimiter=\",\", fmt=\"%.8f\")\n",
    "        return f\"Saved model points CSV: {save_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to save model: {e}\"\n",
    "\n",
    "# ---------- TAB 3: POSE ----------\n",
    "def tab3_reset_clicks():\n",
    "    click_store.clear()\n",
    "    return \"Cleared clicks.\"\n",
    "\n",
    "def tab3_undo_click():\n",
    "    click_store.undo()\n",
    "    return f\"Points: {list(click_store)}\"\n",
    "\n",
    "# --- Point Picker Handler Replacement ---\n",
    "def tab3_on_click(evt: gr.SelectData):\n",
    "    global current_canvas_rgb\n",
    "    x = y = None\n",
    "\n",
    "    if evt is not None and hasattr(evt, \"index\") and evt.index is not None:\n",
    "        try:\n",
    "            x, y = evt.index\n",
    "        except Exception:\n",
    "            x = y = None\n",
    "    if (x is None or y is None) and evt is not None:\n",
    "        if hasattr(evt, \"x\") and hasattr(evt, \"y\"):\n",
    "            x, y = evt.x, evt.y\n",
    "\n",
    "    if current_canvas_rgb is None:\n",
    "        return gr.update(), gr.update()\n",
    "    if x is None or y is None:\n",
    "        return current_canvas_rgb, current_canvas_rgb\n",
    "\n",
    "    h, w = current_canvas_rgb.shape[:2]\n",
    "    u = int(max(0, min(w - 1, x)))\n",
    "    v = int(max(0, min(h - 1, y)))\n",
    "    click_store.add(u, v)  # stores (u, v) for downstream pose, as designed :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "    bgr = cv2.cvtColor(current_canvas_rgb, cv2.COLOR_RGB2BGR)\n",
    "    vis_bgr = draw_indexed_points(bgr, list(click_store))\n",
    "    vis_rgb = cv2.cvtColor(vis_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return vis_rgb, vis_rgb\n",
    "\n",
    "def tab3_load_to_canvas(image_file, intr_file):\n",
    "    global current_canvas_rgb\n",
    "    click_store.clear()\n",
    "    if image_file is None:\n",
    "        return None, \"Load an image first.\"\n",
    "    data = image_file.read() if hasattr(image_file, \"read\") else open(str(image_file), \"rb\").read()\n",
    "    bgr = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    current_canvas_rgb = rgb.copy()            # <-- store for clicks\n",
    "    return rgb, \"Image loaded. Click points in the same order as the model.\"\n",
    "\n",
    "def _prepare_image(image_file, K, dist):\n",
    "    if hasattr(image_file, \"read\"):\n",
    "        data = image_file.read()\n",
    "    else:\n",
    "        data = open(str(image_file), \"rb\").read()\n",
    "    img = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    return img, K, dist\n",
    "\n",
    "def tab3_run_pose(image_file, intrinsics_file, model_file, ransac_thresh, solver_choice):\n",
    "    global R_h_t, R_o_t\n",
    "    if image_file is None or intrinsics_file is None or model_file is None:\n",
    "        return None, None, \"Provide image, intrinsics, and model points.\", None\n",
    "\n",
    "    # load K, dist, XY, and clicks\n",
    "    result = load_calibration_json(intrinsics_file.name)\n",
    "    if isinstance(result, tuple):\n",
    "        K, dist, *rest = result\n",
    "        img_size = rest[0] if rest else None\n",
    "    else:\n",
    "        # fallback: assume dict\n",
    "        K = np.array(result[\"K\"], float)\n",
    "        dist = np.array(result[\"dist\"], float)\n",
    "        img_size = None\n",
    "\n",
    "    XY = load_model_points(model_file.name)\n",
    "    uv = click_store.as_array(float)\n",
    "    if len(uv) != len(XY):\n",
    "        return None, None, f\"Need {len(XY)} clicks; you have {len(uv)}.\", None\n",
    "\n",
    "    # prepare image & intrinsics for projection consistency\n",
    "    img, K_used, dist_used = _prepare_image(image_file, K, dist)\n",
    "    # compute H with RANSAC\n",
    "    H, inliers = dlt_homography_ransac(XY, uv, float(ransac_thresh))\n",
    "\n",
    "    # Homography → Pose\n",
    "    R_h, t_h = pose_from_homography(H, K_used)\n",
    "    # OpenCV pose\n",
    "    if solver_choice == \"solvePnP\":\n",
    "        R_o, t_o = pose_solvepnp(K_used, dist_used, XY, uv)\n",
    "    elif solver_choice == \"decomposeH\":\n",
    "        R_o, t_o = pose_from_h_decompose(H, K_used, XY)\n",
    "    else:\n",
    "        # run both and choose solvePnP for printing\n",
    "        R_o, t_o = pose_solvepnp(K_used, dist_used, XY, uv)\n",
    "\n",
    "    # Overlays\n",
    "    vis_h = overlay_points_and_axes(img, K_used, dist_used, R_h, t_h, XY)\n",
    "    vis_o = overlay_points_and_axes(img, K_used, dist_used, R_o, t_o, XY)\n",
    "\n",
    "    # Errors\n",
    "    err_h = reprojection_error(K_used, dist_used, R_h, t_h, XY, uv)\n",
    "    err_o = reprojection_error(K_used, dist_used, R_o, t_o, XY, uv)\n",
    "\n",
    "    # Save in app state for Tab 4\n",
    "    R_h_t = (R_h, t_h)\n",
    "    R_o_t = (R_o, t_o)\n",
    "\n",
    "    # text\n",
    "    text = (\n",
    "        \"[Homography → Pose]\\n\" + fmt_rt(R_h,t_h) +\n",
    "        f\"\\nErrors(px): mean={err_h['mean']:.3f}, median={err_h['median']:.3f}, max={err_h['max']:.3f}\\n\"\n",
    "        f\"Inliers: {int(np.sum(inliers))}/{len(inliers)}\\n\\n\"\n",
    "        \"[OpenCV Pose]\\n\" + fmt_rt(R_o,t_o) +\n",
    "        f\"\\nErrors(px): mean={err_o['mean']:.3f}, median={err_o['median']:.3f}, max={err_o['max']:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Return numpy arrays for Gradio Image\n",
    "    return vis_h, vis_o, text, f\"Stored 2 poses for comparison.\"\n",
    "\n",
    "# ---------- TAB 4: COMPARE & 3D ----------\n",
    "def tab4_compare_and_viz():\n",
    "    if R_h_t is None and R_o_t is None:\n",
    "        return None, \"No poses computed yet.\"\n",
    "    items = []\n",
    "    if R_h_t and R_o_t:\n",
    "        R_h, t_h = R_h_t\n",
    "        R_o, t_o = R_o_t\n",
    "        dR = rotation_angle_diff(R_h, R_o)\n",
    "        dt = translation_dir_angle(t_h, t_o)\n",
    "        txt = f\"Rotation angle difference: {dR:.3f}°\\nTranslation direction angle: {dt:.3f}°\"\n",
    "        fig = plot_3d_poses([R_h_t, R_o_t], plane_extent=0.2)\n",
    "        img_bgr = fig_to_bgr_array(fig)\n",
    "        return img_bgr, txt\n",
    "    else:\n",
    "        fig = plot_3d_poses([R_h_t or R_o_t], plane_extent=0.2)\n",
    "        who = \"Homography pose\" if R_h_t else \"OpenCV pose\"\n",
    "        img_bgr = fig_to_bgr_array(fig)\n",
    "        return img_bgr, f\"Only {who} available.\"\n",
    "\n",
    "# ---------- APP ----------\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Assignment 2: Pose from a Planar Object (Tabs)\\n*No changes to Assignment 1 files. This app reuses A1 artifacts and adds A2 tabs.*\")\n",
    "\n",
    "    with gr.Tab(\"1) Calibration (A1-like)\"):\n",
    "        with gr.Row():\n",
    "            repo_imgs = gr.CheckboxGroup(choices=tab1_list_repo_images(), label=\"Repo images (data/images/)\")\n",
    "            uploads = gr.Files(label=\"Upload images\")\n",
    "        with gr.Row():\n",
    "            inner_cols = gr.Number(value=9, precision=0, label=\"Inner cols\")\n",
    "            inner_rows = gr.Number(value=6, precision=0, label=\"Inner rows\")\n",
    "            square_m  = gr.Number(value=0.022, label=\"Square size (m)\")\n",
    "        run_cal = gr.Button(\"Run calibration\")\n",
    "        K_txt = gr.Textbox(label=\"K (JSON)\", lines=6)\n",
    "        dist_txt = gr.Textbox(label=\"distCoeffs (JSON)\", lines=3)\n",
    "        gallery = gr.Gallery(label=\"Corners preview\")\n",
    "        summary = gr.Textbox(label=\"Summary (RMS etc.)\", lines=6)\n",
    "\n",
    "        run_cal.click(tab1_run_calibrate, \n",
    "                      inputs=[repo_imgs, uploads, inner_cols, inner_rows, square_m],\n",
    "                      outputs=[K_txt, dist_txt, gallery, summary])\n",
    "\n",
    "        gr.Markdown(\"### Undistort preview\")\n",
    "        und_src = gr.File(label=\"Image to undistort\")\n",
    "        alpha = gr.Slider(0.0, 1.0, value=0.85, step=0.05, label=\"Alpha (balance)\")\n",
    "        und_out = gr.Image(label=\"Undistorted\")\n",
    "        newK_txt = gr.Textbox(label=\"newK (JSON)\", lines=6)\n",
    "        und_btn = gr.Button(\"Undistort this image\")\n",
    "        und_btn.click(tab1_undistort_single, inputs=[und_src, K_txt, dist_txt, alpha], outputs=[und_out, newK_txt])\n",
    "\n",
    "        gr.Markdown(\"### Save intrinsics JSON\")\n",
    "        save_path = gr.Textbox(value=\"sample_data/intrinsics_sample.json\", label=\"Save path\")\n",
    "        save_btn = gr.Button(\"Save intrinsics\")\n",
    "        save_status = gr.Textbox(label=\"Save status\")\n",
    "        save_btn.click(tab1_save_intrinsics, inputs=[save_path, K_txt, dist_txt], outputs=[save_status])\n",
    "\n",
    "    with gr.Tab(\"2) Model Plane\"):\n",
    "        with gr.Row():\n",
    "            cols = gr.Number(value=9, precision=0, label=\"Inner cols\")\n",
    "            rows = gr.Number(value=6, precision=0, label=\"Inner rows\")\n",
    "            size_m = gr.Number(value=0.022, label=\"Square size (m)\")\n",
    "        gen_btn = gr.Button(\"Generate checkerboard model\")\n",
    "        model_preview = gr.Image(label=\"Model preview\")\n",
    "        model_json = gr.Textbox(label=\"Model XY (JSON)\", lines=8)\n",
    "        gen_btn.click(tab2_generate_checker, inputs=[cols, rows, size_m], outputs=[model_preview, model_json])\n",
    "\n",
    "        gr.Markdown(\"**Or upload CSV/JSON**\")\n",
    "        model_file = gr.File(label=\"CSV (X,Y) or JSON ([[X,Y],...])\")\n",
    "        load_btn = gr.Button(\"Load model\")\n",
    "        load_btn.click(tab2_load_model, inputs=[model_file], outputs=[model_preview, model_json])\n",
    "\n",
    "        save_model_path = gr.Textbox(value=\"sample_data/model_points.csv\", label=\"Save model CSV\")\n",
    "        save_model_btn = gr.Button(\"Save model points\")\n",
    "        save_model_status = gr.Textbox(label=\"Save status\")\n",
    "        save_model_btn.click(tab2_save_model, inputs=[save_model_path, model_json], outputs=[save_model_status])\n",
    "\n",
    "    with gr.Tab(\"3) Pose on Image\"):\n",
    "        img_file = gr.File(label=\"Planar scene image\")\n",
    "\n",
    "        intr_file = gr.File(label=\"Intrinsics JSON (K, dist)\")\n",
    "\n",
    "        mdl_file = gr.File(label=\"Model points (CSV/JSON)\")\n",
    "        with gr.Row():\n",
    "            ransac = gr.Slider(0.5, 10.0, value=3.0, step=0.5, label=\"RANSAC threshold (px)\")\n",
    "            solver = gr.Radio([\"solvePnP\", \"decomposeH\", \"both\"], value=\"both\", label=\"OpenCV solver\")\n",
    "\n",
    "        status = gr.Textbox(label=\"Click status / messages\")\n",
    "        # Make canvas explicitly numpy type\n",
    "        img_canvas = gr.Image(type=\"numpy\", label=\"Click here in order\", interactive=True)\n",
    "\n",
    "        with gr.Row():\n",
    "            clear_btn = gr.Button(\"Clear clicks\")\n",
    "            undo_btn  = gr.Button(\"Undo last click\")\n",
    "\n",
    "        img_file.change(tab3_load_to_canvas, inputs=[img_file, intr_file], outputs=[img_canvas, status])\n",
    "        def tab3_on_click_and_json(evt: gr.SelectData):\n",
    "            vis_rgb, _ = tab3_on_click(evt)\n",
    "            pts_json = json.dumps(list(click_store))\n",
    "            return vis_rgb, vis_rgb, pts_json\n",
    "        pts_text = gr.Textbox(label=\"Points (JSON)\", lines=3)\n",
    "        img_canvas.select(tab3_on_click_and_json, outputs=[img_canvas, img_canvas, pts_text])\n",
    "\n",
    "        def tab3_reset_clicks_and_json():\n",
    "            click_store.clear()\n",
    "            return \"Cleared clicks.\", json.dumps(list(click_store))\n",
    "        clear_btn.click(tab3_reset_clicks_and_json, outputs=[status, pts_text])\n",
    "\n",
    "        def tab3_undo_click_and_json():\n",
    "            click_store.undo()\n",
    "            return f\"Points: {list(click_store)}\", json.dumps(list(click_store))\n",
    "        undo_btn.click(tab3_undo_click_and_json, outputs=[status, pts_text])\n",
    "\n",
    "        def tab3_load_to_canvas_and_json(image_file, intr_file):\n",
    "            global current_canvas_rgb\n",
    "            click_store.clear()\n",
    "            if image_file is None:\n",
    "                return None, \"Load an image first.\", json.dumps(list(click_store))\n",
    "            data = image_file.read() if hasattr(image_file, \"read\") else open(str(image_file), \"rb\").read()\n",
    "            bgr = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)\n",
    "            rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            current_canvas_rgb = rgb.copy()\n",
    "            return rgb, \"Image loaded. Click points in the same order as the model.\", json.dumps(list(click_store))\n",
    "        img_file.change(tab3_load_to_canvas_and_json, inputs=[img_file, intr_file], outputs=[img_canvas, status, pts_text])\n",
    "\n",
    "        run_pose_btn = gr.Button(\"Run pose (compute overlays)\")\n",
    "        vis_h = gr.Image(label=\"Homography overlay\")\n",
    "        vis_o = gr.Image(label=\"OpenCV overlay\")\n",
    "        pose_txt = gr.Textbox(label=\"Poses and errors\", lines=14)\n",
    "        stored_msg = gr.Textbox(label=\"Stored state for Tab 4\")\n",
    "\n",
    "        run_pose_btn.click(tab3_run_pose, inputs=[img_file, intr_file, mdl_file, ransac, solver], outputs=[vis_h, vis_o, pose_txt, stored_msg])\n",
    "\n",
    "    with gr.Tab(\"4) Compare & 3D Viz\"):\n",
    "        cmp_btn = gr.Button(\"Show comparison\")\n",
    "        cmp_fig = gr.Image(label=\"3D viz\")\n",
    "        cmp_txt = gr.Textbox(label=\"Numeric comparison\", lines=4)\n",
    "        cmp_btn.click(lambda: tab4_compare_and_viz(), outputs=[cmp_fig, cmp_txt])\n",
    "\n",
    "    demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d5dd7",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02683a5d",
   "metadata": {},
   "source": [
    "### Comparison notes (Assignment 2)\n",
    "\n",
    "- **Accuracy:** OpenCV (solvePnP) is tighter - mean reproj **1.526 px** (median 1.264, max 3.909) vs. Homography→Pose **5.269 px** (median 4.789, max 11.551).\n",
    "- **Pose agreement:** Rotation diff **2.983°**; translation **direction** diff **0.034°** → orientations and pointing direction match well.\n",
    "- **Why the gap:** We estimated **H** on the raw (distorted) image; homography assumes pinhole mapping, so residual distortion becomes model error. `solvePnP` uses `distCoeffs`, explaining distortion and staying tighter.\n",
    "- **RANSAC helped:** **47/54** inliers at 3 px — rejects a few bad/edge clicks; both pipelines become stable.\n",
    "- **More points ≫ 4 corners:** Using **54** well-spread points improves conditioning and averages click noise; with only four, H is noticeably noisier.\n",
    "- **Scale/translation:** With model points in meters, both methods yield compatible translation magnitudes; homography shows a bit more scale jitter across runs.\n",
    "- **Numerical hygiene:** SVD re-orthonormalization and enforcing **det(R)=+1** are important for Homography→Pose; skipping them skews \\(R\\) and worsens overlays.\n",
    "- **Decomposition ambiguity:** `decomposeHomographyMat` can return multiple poses; `solvePnP` avoids cheirality selection and was the more reliable OpenCV baseline here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028482dd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
